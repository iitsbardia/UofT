{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98594d14",
   "metadata": {},
   "source": [
    "# Pre-lecture HW\n",
    "\n",
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6229e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af8857",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "After Trying to acomplishing task 1 in prelecture HW, Chatgpt gave me a code to run as anwser to my question since it couldn't open the dataset himeself\n",
    "\n",
    "here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61bead7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "Size: (891, 12)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from your local file\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Get the columns of the dataset and the size (rows, columns)\n",
    "columns = titanic_data.columns\n",
    "size = titanic_data.shape\n",
    "\n",
    "# Display the columns and the size\n",
    "print(f\"Columns: {columns}\")\n",
    "print(f\"Size: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23dd16c",
   "metadata": {},
   "source": [
    "# Q 2.2\n",
    "\n",
    "Well to be fair GPT gave me a really well rounded anwser but I think i deserve some creddit for good prompts =)\n",
    "\n",
    "in the context of my dataset: \n",
    "\n",
    "- Observations = rows = individual passengers.\n",
    "- Variables = columns = characteristics or data points about each passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1f5e4",
   "metadata": {},
   "source": [
    "I discussed the output with ChatGPT, since I didn't exactly know what \"Size: (891, 12)\" stood for, the data set -even though with some missing values- is a dataset of 891 Titanic passengers and 12 characteristics of each individual represented in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816b3e3e",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "After someback and forth between me and GPT we landed on a decent qway to sumrize the ccolumns\n",
    "\n",
    "1. For numerical columns, I'll provide basic statistics like mean, min, max, and missing values.\n",
    "2. For categorical columns (like Sex, Embarked), I'll show the distribution of unique values and missing data.\n",
    "\n",
    "note that in the list above I refers to ChatGPT\n",
    "\n",
    "One neat problem was the Survived column which was technicly numeric but it used 0s and 1s as boolians\n",
    "\n",
    "simllarly to one before, Pclass is only 1s 2s and 3s, again technicly numeric but it refers to Classes not actual numbers\n",
    "\n",
    "I asked GPT to adjust for thoose \n",
    "\n",
    "Here is the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de150887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary for column: PassengerId\n",
      "  Data type: int64\n",
      "  Missing values: 0\n",
      "  Mean: 446.00\n",
      "  Min: 1\n",
      "  Max: 891\n",
      "  Standard Deviation: 257.35\n",
      "\n",
      "Summary for column: Survived\n",
      "  Data type: int64\n",
      "  Missing values: 0\n",
      "  Survival distribution:\n",
      "Survived\n",
      "0    549\n",
      "1    342\n",
      "Name: count, dtype: int64\n",
      "  Survival rate: 38.38%\n",
      "\n",
      "Summary for column: Pclass\n",
      "  Data type: int64\n",
      "  Missing values: 0\n",
      "  Passenger Class distribution:\n",
      "Pclass\n",
      "3    491\n",
      "1    216\n",
      "2    184\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary for column: Name\n",
      "  Data type: object\n",
      "  Missing values: 0\n",
      "  Unique values:\n",
      "Name\n",
      "Braund, Mr. Owen Harris                     1\n",
      "Boulos, Mr. Hanna                           1\n",
      "Frolicher-Stehli, Mr. Maxmillian            1\n",
      "Gilinski, Mr. Eliezer                       1\n",
      "Murdlin, Mr. Joseph                         1\n",
      "                                           ..\n",
      "Kelly, Miss. Anna Katherine \"Annie Kate\"    1\n",
      "McCoy, Mr. Bernard                          1\n",
      "Johnson, Mr. William Cahoone Jr             1\n",
      "Keane, Miss. Nora A                         1\n",
      "Dooley, Mr. Patrick                         1\n",
      "Name: count, Length: 891, dtype: int64\n",
      "\n",
      "Summary for column: Sex\n",
      "  Data type: object\n",
      "  Missing values: 0\n",
      "  Unique values:\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary for column: Age\n",
      "  Data type: float64\n",
      "  Missing values: 177\n",
      "  Mean: 29.70\n",
      "  Min: 0.42\n",
      "  Max: 80.0\n",
      "  Standard Deviation: 14.53\n",
      "\n",
      "Summary for column: SibSp\n",
      "  Data type: int64\n",
      "  Missing values: 0\n",
      "  Mean: 0.52\n",
      "  Min: 0\n",
      "  Max: 8\n",
      "  Standard Deviation: 1.10\n",
      "\n",
      "Summary for column: Parch\n",
      "  Data type: int64\n",
      "  Missing values: 0\n",
      "  Mean: 0.38\n",
      "  Min: 0\n",
      "  Max: 6\n",
      "  Standard Deviation: 0.81\n",
      "\n",
      "Summary for column: Ticket\n",
      "  Data type: object\n",
      "  Missing values: 0\n",
      "  Unique values:\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: count, Length: 681, dtype: int64\n",
      "\n",
      "Summary for column: Fare\n",
      "  Data type: float64\n",
      "  Missing values: 0\n",
      "  Mean: 32.20\n",
      "  Min: 0.0\n",
      "  Max: 512.3292\n",
      "  Standard Deviation: 49.69\n",
      "\n",
      "Summary for column: Cabin\n",
      "  Data type: object\n",
      "  Missing values: 687\n",
      "  Unique values:\n",
      "Cabin\n",
      "NaN            687\n",
      "C23 C25 C27      4\n",
      "G6               4\n",
      "B96 B98          4\n",
      "C22 C26          3\n",
      "              ... \n",
      "E34              1\n",
      "C7               1\n",
      "C54              1\n",
      "E36              1\n",
      "C148             1\n",
      "Name: count, Length: 148, dtype: int64\n",
      "\n",
      "Summary for column: Embarked\n",
      "  Data type: object\n",
      "  Missing values: 2\n",
      "  Unique values:\n",
      "Embarked\n",
      "S      644\n",
      "C      168\n",
      "Q       77\n",
      "NaN      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from your local file\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Basic summary for each column including missing values\n",
    "def summarize_column(col):\n",
    "    print(f\"\\nSummary for column: {col.name}\")\n",
    "    print(f\"  Data type: {col.dtype}\")\n",
    "    print(f\"  Missing values: {col.isnull().sum()}\")\n",
    "\n",
    "    # Special handling for Survived (binary column)\n",
    "    if col.name == 'Survived':\n",
    "        print(f\"  Survival distribution:\\n{col.value_counts()}\")\n",
    "        survival_rate = col.mean() * 100\n",
    "        print(f\"  Survival rate: {survival_rate:.2f}%\")\n",
    "    \n",
    "    # Special handling for Pclass (categorical class column)\n",
    "    elif col.name == 'Pclass':\n",
    "        print(f\"  Passenger Class distribution:\\n{col.value_counts()}\")\n",
    "    \n",
    "    # If numeric, summarize like normal numeric data\n",
    "    elif pd.api.types.is_numeric_dtype(col):\n",
    "        print(f\"  Mean: {col.mean():.2f}\")\n",
    "        print(f\"  Min: {col.min()}\")\n",
    "        print(f\"  Max: {col.max()}\")\n",
    "        print(f\"  Standard Deviation: {col.std():.2f}\")\n",
    "    else:\n",
    "        # Otherwise, treat it as categorical and show unique values\n",
    "        print(f\"  Unique values:\\n{col.value_counts(dropna=False)}\")\n",
    "\n",
    "# Loop through all columns in the dataset and summarize\n",
    "for col_name in titanic_data.columns:\n",
    "    summarize_column(titanic_data[col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b615f",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "Once again, Hats off to GPT for giving such complite anwser im basicly just writing it in md, but here it is:\n",
    "\n",
    "- **Non-numeric variables are excluded from df.describe()**\n",
    "    - If you have 12 columns but 5 of them are non-numeric, df.describe() will only analyze the remaining 7 numeric columns, leading to fewer columns in the describe() output.\n",
    "    - df.describe(), by default, only analyzes numeric variables, so it will exclude non-numeric (categorical) columns like Name, Sex, Ticket, Cabin\n",
    "\n",
    "\n",
    "- **Missing numeric values will not be analyized by df.describe()**\n",
    "    - df.describe() gives summaries like mean, min, max, and counts only non-missing (valid) entries for each numeric column.\n",
    "    - in casse of our dataset, the analisis above is only for existing ages since our set has a lot of missing ages, the min max and mean are for only the valid ones\n",
    "    \n",
    "- df.shape reports the total number of rows and columns in your dataset.\n",
    "    \n",
    "to oversimlify it but in my own words, in case of non-numeric vars, df.describe() will not analyze and in case of missing numeric vars df.describe() will only count the values that are there. To the contrary df.shape will count every row and column regardless of it being numeric or not and missing values or not it will give the overall number of rows and columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e5190",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "#### Method:\n",
    "- A method is a **function** that is associated with an object, and it can perform operations or actions on the object’s data, typically modifying or providing a new view of the data.\n",
    "\n",
    "#### Attribute:\n",
    "- An attribute is a **property** of an object that stores data or state information about the object.\n",
    "\n",
    "above you see the gpt responce but it think it's best said that an atribiute like shape is something that in oop is associathed with our object at initilazation and the maybe changed but a method is a functtion that we can use on our object.\n",
    "\n",
    "methods might take arguments and perform an operation but attribut are accessed directly from the object itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86998824",
   "metadata": {},
   "source": [
    "# Chatbot summary pt.1 (1-5)\n",
    "\n",
    "Here is the link to my ChatGPT intraction :\n",
    "https://chatgpt.com/share/dcb58cec-d4bd-4c51-8b26-59c131f95bad\n",
    "\n",
    "[Click Here](https://chatgpt.com/share/dcb58cec-d4bd-4c51-8b26-59c131f95bad)\n",
    "\n",
    "---\n",
    "\n",
    "#### Understanding the Titanic Dataset Structure\n",
    "\n",
    "Objective: To gain a foundational understanding of the Titanic dataset's structure and how to interpret its dimensions and variables.\n",
    "\n",
    "#### Dataset Dimensions:\n",
    "\n",
    "- Rows (Observations): Each of the 891 rows represents an individual passenger aboard the Titanic.\n",
    "- Columns (Variables): The 12 columns represent different characteristics (variables) describing each passenger (e.g., PassengerId, Survived, Pclass, Age).\n",
    "\n",
    "#### Explaining Observations and Variables:\n",
    "\n",
    "- Observations: Refers to individual entries in the dataset; in this case, individual Titanic passengers.\n",
    "- Variables: Refers to the features or attributes recorded for each observation, such as survival status, class, and age.\n",
    "\n",
    "#### Discrepancies in Data Analysis:\n",
    "\n",
    "- Non-Numeric Variables: df.shape reports all columns, but df.describe() by default only includes numeric variables. This results in fewer columns being analyzed by df.describe().\n",
    "- Missing Values in Numeric Variables: df.shape counts all rows, but df.describe() counts only non-missing entries for each column. This can lead to discrepancies in the \"count\" between these two methods, particularly noticeable in columns with missing data like Age.\n",
    "\n",
    "#### Summary Statistics:\n",
    "\n",
    "Discussed how to generate and interpret summary statistics for both numeric and categorical data within the dataset, adjusting the approach based on the nature of each variable (e.g., treating Survived as a categorical variable).\n",
    "\n",
    "#### Code Adjustments:\n",
    "Adjusted Python code to correctly summarize the dataset, accounting for the specific nature of binary and categorical columns like Survived and Pclass.\n",
    "\n",
    "#### Conclusion:\n",
    "The Titanic dataset was dissected to understand its structure and the characteristics of its variables. Practical steps to summarize the dataset were discussed, and Python code was provided and adjusted to handle specific data types accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fd993",
   "metadata": {},
   "source": [
    "# Post lecture HW\n",
    "\n",
    "- note: since i did the diffrent sections on diffrent days i had 2 diffrent GPT settions but i tried my best to give the context of my first settion to my second chat\n",
    "\n",
    "## Q6\n",
    "\n",
    "fairly straightforward\n",
    "\n",
    "1. count: The number of non-missing (non-NaN) entries for each variable.\n",
    "2. mean: The average value of the variable.\n",
    "3. std: The standard deviation, a measure of the dispersion or spread of the values.\n",
    "4. min: The minimum value of the variable.\n",
    "5. 25%: The first quartile (Q1), which is the value below which 25% of the data falls.\n",
    "6. 50%: The median (second quartile, Q2), which is the middle value when data is sorted.\n",
    "7. 75%: The third quartile (Q3), which is the value below which 75% of the data falls.\n",
    "8. max: The maximum value of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5efc3",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "1. Dataset with multiple columns, and we want to remove rows that contain missing values in any of these columns because those rows would lead to inaccurate analysis.This method is preferred because it preserves the structure of all columns but removes only those rows where one or more cells are missing data.\n",
    "\n",
    "2. Large dataset with some columns containing many missing values, and those columns are deemed unnecessary or irrelevantfor analysis.This method is preferred when we decide to drop specific columns that are either not needed or have too many missing values.\n",
    "\n",
    "3. Applying del df['col'] before df.dropna() can be crucial because removing irrelevant or highly missing columns first can prevent the unnecessary loss of valuable data in other columns.\n",
    "\n",
    "4. approach:\n",
    "\n",
    "- Remove the Cabin Column Entirely: Since the Cabin column has a significant number of missing values and is generally less informative for most analyses (e.g., predicting survival), it makes sense to delete this column altogether. \n",
    "\n",
    "- Handle the Age Column Separately\n",
    "\n",
    "\n",
    "I asked GPT to write the code for this aproach and provide a before and after summary =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e241413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before Cleaning Report:\n",
      "  Total Rows: 891\n",
      "  Total Columns: 12\n",
      "  Missing Values Per Column:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "After Cleaning Report:\n",
      "  Total Rows: 889\n",
      "  Total Columns: 11\n",
      "  Missing Values Per Column:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset from the provided URL\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Function to provide a simplified report on the dataset\n",
    "def simplified_report(df, title):\n",
    "    print(f\"\\n{title} Report:\")\n",
    "    print(f\"  Total Rows: {df.shape[0]}\")\n",
    "    print(f\"  Total Columns: {df.shape[1]}\")\n",
    "    print(f\"  Missing Values Per Column:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Initial simplified report before data cleaning\n",
    "simplified_report(titanic_data, \"Before Cleaning\")\n",
    "\n",
    "# Step 1: Delete the 'Cabin' column due to a high number of missing values and low relevance\n",
    "del titanic_data['Cabin']\n",
    "\n",
    "# Step 2: Impute missing values in 'Age' with the median value\n",
    "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
    "\n",
    "# Step 3: Drop rows with any remaining missing values\n",
    "titanic_data.dropna(inplace=True)\n",
    "\n",
    "# Simplified report after data cleaning\n",
    "simplified_report(titanic_data, \"After Cleaning\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799147e",
   "metadata": {},
   "source": [
    "## Q8 - 1\n",
    "\n",
    "In my own Words:\n",
    "\n",
    "what \"df.groupby(\"col1\")[\"col2\"].describe()\" does is generate and show \"count, mean, ..., max\" of col2, for each unique value of col1. \n",
    "\n",
    "#### Summary of Imaginary Dataset and Demonstration\n",
    "\n",
    "- We created an imaginary dataset to analyze student GPAs from four different universities: University of Toronto (UofT), University of Waterloo (UWaterloo), York University (York), and Western University (Western). Each university had 20 students, making a total of 80 students in the dataset.\n",
    "\n",
    "- Dataset Structure:\n",
    "    - University: Represents the name of the university (UofT, UWaterloo, York, Western).\n",
    "    - GPA: Represents the GPA of each student, randomly generated based on a normal distribution with different means and standard deviations for each university.\n",
    "\n",
    "- Objective:\n",
    "    - To demonstrate the use of df.groupby(\"col1\")[\"col2\"].describe() to analyze the distribution of GPAs (GPA) for students from each university (University).\n",
    "\n",
    "Here is the ChatGPT code bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a876d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count      mean       std       min       25%       50%       75%  \\\n",
      "University                                                                      \n",
      "UWaterloo    20.0  3.093610  0.387215  2.416132  2.767587  3.096506  3.279945   \n",
      "UofT         20.0  3.448610  0.288009  2.926016  3.305384  3.429756  3.652453   \n",
      "Western      20.0  2.981162  0.667253  1.428153  2.687604  3.015366  3.488922   \n",
      "York         20.0  2.786655  0.410424  1.918480  2.542645  2.813930  3.121687   \n",
      "\n",
      "                 max  \n",
      "University            \n",
      "UWaterloo   3.940911  \n",
      "UofT        3.973764  \n",
      "Western     3.938786  \n",
      "York        3.328561  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create an imaginary dataset with 100 students (20 from each university)\n",
    "data = {\n",
    "    'University': (['UofT'] * 20) + (['UWaterloo'] * 20) + (['York'] * 20) + (['Western'] * 20),\n",
    "    'GPA': np.concatenate([\n",
    "        np.random.normal(3.5, 0.3, 20),  # GPAs for UofT students\n",
    "        np.random.normal(3.2, 0.4, 20),  # GPAs for UWaterloo students\n",
    "        np.random.normal(2.8, 0.5, 20),  # GPAs for York students\n",
    "        np.random.normal(3.0, 0.6, 20)   # GPAs for Western students\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_students = pd.DataFrame(data)\n",
    "\n",
    "# Group by 'University' and describe the 'GPA' column\n",
    "gpa_description_by_university = df_students.groupby(\"University\")[\"GPA\"].describe()\n",
    "\n",
    "# Display the result\n",
    "print(gpa_description_by_university)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1172d49",
   "metadata": {},
   "source": [
    "## Q8 - 2\n",
    "\n",
    "#### Difference Between `df.describe()` and `df.groupby(\"col1\")[\"col2\"].describe()` Counts:\n",
    "\n",
    "1. **`df.describe()` Count**:\n",
    "   - Shows the number of non-missing (non-NaN) values **for each column** in the entire dataset.\n",
    "   - If a column has missing data, its `count` will be less than the total number of rows. This tells you how much data is available for each column overall.\n",
    "\n",
    "2. **`df.groupby(\"col1\")[\"col2\"].describe()` Count**:\n",
    "   - Shows the number of non-missing values **for `col2` within each group** defined by the unique values of `col1`.\n",
    "   - It tells you how much data is available for `col2` in each category of `col1` (e.g., grouping by passenger class and counting ages in the Titanic dataset).\n",
    "\n",
    "#### Key Difference:\n",
    "- `df.describe()` provides a summary of missing data **for each column** in the entire dataset.\n",
    "- `df.groupby(\"col1\")[\"col2\"].describe()` provides a summary of missing data **for `col2` within each group** of `col1`.\n",
    "\n",
    "#### Why This Matters:\n",
    "- `df.describe()` helps you see overall data completeness for each column.\n",
    "- `df.groupby(\"col1\")[\"col2\"].describe()` helps you understand data completeness and distribution **within specific groups**, which is useful for more detailed analysis.\n",
    "\n",
    "This distinction is important because one summarizes data for the whole dataset, while the other focuses on grouped subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc1a71",
   "metadata": {},
   "source": [
    "# Q8 -3\n",
    "\n",
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c73d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Omitted: import pandas as pd\n",
    "\n",
    "# Create a DataFrame without importing pandas\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d06206c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Now this works correctly\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c40608",
   "metadata": {},
   "source": [
    "## B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d9f0cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Mistyped filename in the URL\u001b[39;00m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/datasciencedojo/datasets/master/titanics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Incorrect filename 'titanics.csv'\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m titanic_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:718\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    715\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    717\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 718\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    727\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:372\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    371\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    373\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:274\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mistyped filename in the URL\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanics.csv'  # Incorrect filename 'titanics.csv'\n",
    "titanic_data = pd.read_csv(url)  # This will raise an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e630dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'  # Correct filename 'titanic.csv'\n",
    "titanic_data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c595bd0e",
   "metadata": {},
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f0613e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Titanic_Data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Incorrectly using the DataFrame variable\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Intentional typo in the variable name (should be 'titanic_data')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mTitanic_Data\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Titanic_Data' is not defined"
     ]
    }
   ],
   "source": [
    "# Incorrectly using the DataFrame variable\n",
    "# Intentional typo in the variable name (should be 'titanic_data')\n",
    "Titanic_Data.groupby(\"Pclass\")[\"Age\"].describe()  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "112f0e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214.0</td>\n",
       "      <td>36.688879</td>\n",
       "      <td>14.142850</td>\n",
       "      <td>0.92</td>\n",
       "      <td>28.00</td>\n",
       "      <td>35.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>184.0</td>\n",
       "      <td>29.765380</td>\n",
       "      <td>13.581096</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>491.0</td>\n",
       "      <td>25.932627</td>\n",
       "      <td>10.697676</td>\n",
       "      <td>0.42</td>\n",
       "      <td>20.25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min    25%   50%   75%   max\n",
       "Pclass                                                            \n",
       "1       214.0  36.688879  14.142850  0.92  28.00  35.0  47.0  80.0\n",
       "2       184.0  29.765380  13.581096  0.67  23.00  28.0  36.0  70.0\n",
       "3       491.0  25.932627  10.697676  0.42  20.25  28.0  29.0  74.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correctly using the DataFrame variable\n",
    "titanic_data.groupby(\"Pclass\")[\"Age\"].describe()  # Correct usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f55e39",
   "metadata": {},
   "source": [
    "## D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b46539f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1838234429.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    titanic_data = pd.read_csv(url  # Missing closing parenthesis\u001b[0m\n\u001b[0m                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "\n",
    "# Forgetting the closing parenthesis in the read_csv function\n",
    "titanic_data = pd.read_csv(url  # Missing closing parenthesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebf7c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "\n",
    "# Correcting by adding the closing parenthesis\n",
    "titanic_data = pd.read_csv(url)  # Now this works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d599ee9",
   "metadata": {},
   "source": [
    "## E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0b4a250",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_52/1411517687.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitanic_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Mistyping 'groupby' as 'group_by'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtitanic_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will raise an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Mistyping 'groupby' as 'group_by'\n",
    "titanic_data.group_by(\"Pclass\")[\"Age\"].describe()  # This will raise an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ebbaff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting the function name 'groupby'\n",
    "titanic_data.groupby(\"Pclass\")[\"Age\"].describe()  # Now this works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bc2a030",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SeriesGroupBy' object has no attribute 'describle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mistyping 'describe' as 'describle'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtitanic_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPclass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescrible\u001b[49m()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1312\u001b[0m, in \u001b[0;36mGroupBy.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[attr]\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1314\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SeriesGroupBy' object has no attribute 'describle'"
     ]
    }
   ],
   "source": [
    "# Mistyping 'describe' as 'describle'\n",
    "titanic_data.groupby(\"Pclass\")[\"Age\"].describle()  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f1fe570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186.0</td>\n",
       "      <td>38.233441</td>\n",
       "      <td>14.802856</td>\n",
       "      <td>0.92</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173.0</td>\n",
       "      <td>29.877630</td>\n",
       "      <td>14.001077</td>\n",
       "      <td>0.67</td>\n",
       "      <td>23.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355.0</td>\n",
       "      <td>25.140620</td>\n",
       "      <td>12.495398</td>\n",
       "      <td>0.42</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Pclass                                                           \n",
       "1       186.0  38.233441  14.802856  0.92  27.0  37.0  49.0  80.0\n",
       "2       173.0  29.877630  14.001077  0.67  23.0  29.0  36.0  70.0\n",
       "3       355.0  25.140620  12.495398  0.42  18.0  24.0  32.0  74.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correcting the function name 'describe'\n",
    "titanic_data.groupby(\"Pclass\")[\"Age\"].describe()  # Now this works correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f29612",
   "metadata": {},
   "source": [
    "## F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4a0f2ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m titanic_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Mistyping the column name 'Sex' as 'sex' in groupby\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtitanic_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Mistyping the column name 'Sex' as 'sex' in groupby\n",
    "titanic_data.groupby(\"sex\")[\"Age\"].describe()  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbb4bd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct column names for groupby and selection\n",
    "titanic_data.groupby(\"Sex\")[\"Age\"].describe()  # Correct groupby column 'Sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bc63293",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mistyping the column name 'age' as 'Age' in the column selection\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtitanic_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "# Mistyping the column name 'age' as 'Age' in the column selection\n",
    "titanic_data.groupby(\"sex\")[\"age\"].describe()  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8476ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct column names for groupby and selection\n",
    "titanic_data.groupby(\"Sex\")[\"Age\"].describe()  # Correct column selection 'Age'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4865c950",
   "metadata": {},
   "source": [
    "## G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "401fcb87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m titanic_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Missing quotes around 'sex' in groupby\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m titanic_data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43msex\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sex' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Correct URL to load the Titanic dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Missing quotes around 'sex' in groupby\n",
    "titanic_data.groupby(sex)[\"Age\"].describe()  # This will raise an error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "496bb457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct column name usage with quotes\n",
    "titanic_data.groupby(\"Sex\")[\"Age\"].describe()  # Correct usage with quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31624377",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Missing quotes around 'Age' in column selection\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtitanic_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[Age]\u001b[38;5;241m.\u001b[39mdescribe()  \u001b[38;5;66;03m# This will raise an error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "# Missing quotes around 'Age' in column selection\n",
    "titanic_data.groupby(\"sex\")[Age].describe()  # This will raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c9f329f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "Sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct column name usage with quotes\n",
    "titanic_data.groupby(\"Sex\")[\"Age\"].describe()  # Correct usage with quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9904cb",
   "metadata": {},
   "source": [
    "## Troubleshooting Code: ChatGPT vs. Google\n",
    "\n",
    "Alright, here’s the deal. When I’m stuck with coding issues, I’d rather use ChatGPT over Google. Why? Because with Google, I have to dig through a bunch of websites, read endless threads, and sometimes still not find exactly what I need. It’s like a scavenger hunt.\n",
    "\n",
    "With ChatGPT, it’s more like having a friend who knows their stuff and walks me through the problem step-by-step. It’s way more direct and less frustrating. Plus, I can ask follow-up questions without jumping from page to page. So yeah, ChatGPT feels more like a human tutor, making troubleshooting less of a headache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746da26",
   "metadata": {},
   "source": [
    "## Q9\n",
    "\n",
    "**Somewhat**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1968ce",
   "metadata": {},
   "source": [
    "# Chatbot summary pt.2 (6-9)\n",
    "\n",
    "Here is the link to my ChatGPT intraction :\n",
    "https://chatgpt.com/share/5119ba84-18b7-4a42-a1a3-27335f143ebb\n",
    "\n",
    "[Click Here](https://chatgpt.com/share/5119ba84-18b7-4a42-a1a3-27335f143ebbd)\n",
    "\n",
    "### Chatbot Summary: Data Cleaning and Error Handling with the Titanic Dataset\n",
    "\n",
    "#### Objective:\n",
    "To clean the Titanic dataset by handling missing values effectively and then intentionally introduce and fix common coding errors to improve data analysis and debugging skills.\n",
    "\n",
    "#### Key Steps Taken:\n",
    "\n",
    "1. **Understanding the Data**:\n",
    "   - Reviewed the Titanic dataset's structure, identifying that the `Cabin` and `Age` columns had a significant number of missing values, while most other columns had very few or none.\n",
    "\n",
    "2. **Decided on the Data Cleaning Approach**:\n",
    "   - **Remove the `Cabin` column**: Due to a high number of missing values (687 out of 891) and its low relevance to most analyses.\n",
    "   - **Impute missing values in the `Age` column**: Fill missing `Age` values with the median to maintain data integrity without introducing bias.\n",
    "   - **Drop remaining rows with missing values**: After handling `Cabin` and `Age`, drop any rows with missing values in other columns to ensure a clean dataset.\n",
    "\n",
    "3. **Implemented the Data Cleaning Steps**:\n",
    "   - Removed the `Cabin` column using `del df['Cabin']`.\n",
    "   - Imputed missing `Age` values using the median with `df['Age'].fillna(df['Age'].median(), inplace=True)`.\n",
    "   - Dropped any remaining rows with missing values using `df.dropna(inplace=True)`.\n",
    "\n",
    "4. **Created a Simplified Before and After Report**:\n",
    "   - Introduced a concise reporting function to provide a clear summary of the dataset's state before and after cleaning, including the number of rows, columns, and missing values per column.\n",
    "\n",
    "#### Results:\n",
    "- The dataset was successfully cleaned, with all missing values addressed. The `Cabin` column was removed, `Age` values were imputed, and remaining rows with missing values were dropped, resulting in a dataset ready for further analysis.\n",
    "\n",
    "#### Next Steps:\n",
    "- Proceed with more advanced data analysis, such as feature engineering, data visualization, or building predictive models using the cleaned Titanic dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### Error Handling and Debugging Exercises\n",
    "\n",
    "After cleaning the dataset, we explored various intentional errors and their fixes to enhance our understanding of common coding issues and debugging techniques:\n",
    "\n",
    "1. **Forget to Import a Library**:\n",
    "   - **Error Created**: Removed the `import pandas as pd` line, which caused a `NameError: name 'pd' is not defined`.\n",
    "   - **Solution**: Re-added the `import pandas as pd` line to fix the error.\n",
    "\n",
    "2. **Incorrect Filename in URL**:\n",
    "   - **Error Created**: Changed the filename in the URL from `titanic.csv` to `titanics.csv`, resulting in a `FileNotFoundError`.\n",
    "   - **Solution**: Corrected the filename in the URL back to `titanic.csv`.\n",
    "\n",
    "3. **Typo in URL Domain or Path**:\n",
    "   - **Error Created**: Introduced typos in different parts of the URL (e.g., domain name, path), resulting in various errors like `URLError` and `HTTPError 404: Not Found`.\n",
    "   - **Solution**: Corrected the typos in the URL.\n",
    "\n",
    "4. **Using a Variable Before Assignment**:\n",
    "   - **Error Created**: Misnamed the DataFrame variable, e.g., `Titanic_Data` instead of `titanic_data`, causing a `NameError`.\n",
    "   - **Solution**: Corrected the variable name to `titanic_data`.\n",
    "\n",
    "5. **Missing Parenthesis in Function Call**:\n",
    "   - **Error Created**: Removed a closing parenthesis in a function call like `pd.read_csv(url`, resulting in a `SyntaxError: unexpected EOF while parsing`.\n",
    "   - **Solution**: Added the missing parenthesis to complete the function call.\n",
    "\n",
    "6. **Mistyped Function Names**:\n",
    "   - **Error Created**: Misspelled function names like `group_by` instead of `groupby` and `describle` instead of `describe`, causing `AttributeError`.\n",
    "   - **Solution**: Corrected the function names to `groupby` and `describe`.\n",
    "\n",
    "7. **Using a Column Name Not in the Data**:\n",
    "   - **Error Created**: Used incorrect column names in `groupby` and column selection, e.g., `\"Sex\"` instead of `\"sex\"` and `\"age\"` instead of `\"Age\"`, resulting in `KeyError`.\n",
    "   - **Solution**: Corrected the column names to match exactly those in the DataFrame.\n",
    "\n",
    "8. **Forgetting to Put Column Names in Quotes**:\n",
    "   - **Error Created**: Omitted quotes around column names, such as `groupby(sex)` instead of `groupby(\"sex\")`, causing a `NameError`.\n",
    "   - **Solution**: Added quotes around column names to ensure they are treated as strings.\n",
    "\n",
    "### Conclusion:\n",
    "This exercise demonstrated how to clean a dataset effectively and handle missing values while providing practical experience in identifying, creating, and fixing common programming errors. The process strengthened understanding of debugging techniques and helped develop best practices for data analysis using pandas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
