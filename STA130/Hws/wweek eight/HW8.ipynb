{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA130 Homework 08\n",
    "\n",
    "Due Date: November 21, 2024\n",
    "\n",
    "## 1. Start a ChatBot session to understand what a *Classification Decision Tree* is:\n",
    "- **a.** Ask the ChatBot to describe the type of problem a *Classification Decision Tree* addresses and provide some examples of real-world applications.\n",
    "- **b.** Make sure you understand the difference between how a *Classification Decision Tree* makes *(classification) predictions* versus how *Multiple Linear Regression* makes *(regression) predictions*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore real-world application scenarios for each of the following *metrics*:\n",
    "- **Accuracy**\n",
    "- **Sensitivity**\n",
    "- **Specificity**\n",
    "- **Precision**\n",
    "Provide examples of real-world scenarios where each metric would be particularly useful, and explain your rationale for each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA) on the Amazon Books dataset:\n",
    "- Remove `Weight_oz`, `Width`, and `Height`.\n",
    "- Drop all remaining rows with `NaN` entries.\n",
    "- Set `Pub year` and `NumPages` to have the type `int`, and `Hard_or_Paper` to have the type `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Remove columns and rows with NaN values\n",
    "ab_reduced_noNaN = ab.drop(columns=['Weight_oz', 'Width', 'Height'])\n",
    "ab_reduced_noNaN.dropna(inplace=True)\n",
    "\n",
    "# Convert columns to the appropriate data types\n",
    "ab_reduced_noNaN['Pub year'] = ab_reduced_noNaN['Pub year'].astype(int)\n",
    "ab_reduced_noNaN['NumPages'] = ab_reduced_noNaN['NumPages'].astype(int)\n",
    "ab_reduced_noNaN['Hard_or_Paper'] = ab_reduced_noNaN['Hard_or_Paper'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create an 80/20 split with 80% of the data as a training set and 20% as a test set.\n",
    "- Train a **DecisionTreeClassifier** model using `List Price` to predict whether a book is a hardcover or paperback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "\n",
    "# Create the 80/20 split\n",
    "y = pd.get_dummies(ab_reduced_noNaN['Hard_or_Paper'])['H']\n",
    "X = ab_reduced_noNaN[['List Price']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classification tree model\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the tree\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=['List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\", format=\"png\")\n",
    "graph.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize the classification decision tree with `NumPages`, `Thick`, and `List Price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ab_reduced_noNaN[['NumPages', 'Thick', 'List Price']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classification tree model\n",
    "clf2 = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the tree\n",
    "dot_data = tree.export_graphviz(clf2, out_file=None, feature_names=['NumPages', 'Thick', 'List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree_2\", format=\"png\")\n",
    "graph.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create confusion matrices for both models `clf` and `clf2` using the test data and report the sensitivity, specificity, and accuracy for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Create confusion matrices for clf and clf2\n",
    "y_pred_clf = clf.predict(X_test)\n",
    "y_pred_clf2 = clf2.predict(X_test)\n",
    "\n",
    "conf_matrix_clf = confusion_matrix(y_test, y_pred_clf)\n",
    "conf_matrix_clf2 = confusion_matrix(y_test, y_pred_clf2)\n",
    "\n",
    "# Display confusion matrices\n",
    "ConfusionMatrixDisplay(conf_matrix_clf, display_labels=[\"Paper\", \"Hard\"]).plot()\n",
    "ConfusionMatrixDisplay(conf_matrix_clf2, display_labels=[\"Paper\", \"Hard\"]).plot()\n",
    "\n",
    "# Calculate sensitivity, specificity, and accuracy for each model\n",
    "def calculate_metrics(conf_matrix):\n",
    "    TP = conf_matrix[1, 1]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "    specificity = TN / (TN + FP)\n",
 "    return accuracy, sensitivity, specificity\n",
    "\n",
    "metrics_clf = calculate_metrics(conf_matrix_clf)\n",
    "metrics_clf2 = calculate_metrics(conf_matrix_clf2)\n",
    "\n",
    "print(f\"Model clf - Accuracy: {metrics_clf[0]}, Sensitivity: {metrics_clf[1]}, Specificity: {metrics_clf[2]}\")\n",
    "print(f\"Model clf2 - Accuracy: {metrics_clf2[0]}, Sensitivity: {metrics_clf2[1]}, Specificity: {metrics_clf2[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Explain the differences between the two confusion matrices and why the models `clf` and `clf2` perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize feature importances for `clf2` and determine which predictor variable is most important for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances for clf2\n",
    "importances = clf2.feature
